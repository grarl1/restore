% !TeX spellcheck = en_US
\documentclass[a4paper, runningheads]{llncs}

% Full page margins
\usepackage{fullpage}

% For language
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

% For figures
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% For tables
\usepackage[dvipsnames,table,xcdraw]{xcolor}
\usepackage{multirow}
\renewcommand{\arraystretch}{1.2}

% Glossary
\usepackage[acronym]{glossaries}
\makenoidxglossaries

% Acronyms
\newacronym{dl}{DL}{Deep learning}
\newacronym{relu}{ReLU}{Rectified Linear Unit}
\newacronym{ann}{ANN}{artificial neural network}
\newacronym{sisr}{SISR}{single image super-resolution}
\newacronym{hr}{HR}{high resolution}
\newacronym{lr}{LR}{low resolution}
\newacronym{cnn}{CNN}{convolutional neural network}
\newacronym{srcnn}{SRCNN}{Super-Resolution Convolutional Neural Network}
\newacronym{fsrcnn}{FSRCNN}{Fast Super-Resolution Convolutional Neural Network}
\newacronym{ircnn}{IRCNN}{Image Restoration Convolutional Neural Network}
\newacronym{psnr}{PSNR}{Peak Signal to Noise Ratio}
\newacronym{ssim}{SSIM}{structural similarity}
\newacronym{gpu}{GPU}{graphics processing unit}
\newacronym{dncnn}{DnCNN}{Denoising Convolutional Neural Network}
\newacronym{gan}{GAN}{Generative Adversarial Networks}
\newacronym{lapsrn}{LapSRN}{Deep Laplacian Pyramid Super-Resolution Network}
\newacronym{vdsr}{VDSR}{Very Deep Super-Resolution}
\newacronym{espcn}{ESPCN}{Efficient Sub-Pixel Convolutional Neural Network}
\newacronym{edsr}{EDSR}{Enhanced Deep Super-Resolution}
\newacronym{mrf}{MRF}{Markov random fields}
\newacronym{bm3d}{BM3D}{Block-matching and 3D filtering}
\newacronym{ncsr}{NCSR}{Nonlocally Centralized Sparse Representation}
\newacronym{hqs}{HQS}{Half Quadratic Splitting}
\newacronym{tnrd}{TRND}{Trainable Nonlinear Reaction Diffusion}
\newacronym{deepam}{DeepAM}{Deeply aggregated Alternating Minimization}
\newacronym{prelu}{PReLU}{Parametric Rectified Linear Unit}
\newacronym{nhwc}{NHWC}{number of samples, height, width, channels}
\newacronym{nchw}{NCHW}{number of samples, channels, height, width}
\newacronym{rgb}{RGB}{Red, Green, Blue}
\newacronym{ycbcr}{YCbCr}{$YC_bC_r$: $Y$, luma component, $C_b$, blue-difference component, $C_r$, red-difference component}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{sgd}{SGD}{stochastic gradient descent}
\newacronym{os}{OS}{operative system}


% For bibliography
\usepackage[backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{references.bib}

% For links
\usepackage{hyperref}
\usepackage{cleveref}
\hypersetup {
	linkcolor  = MidnightBlue,
	citecolor  = MidnightBlue,
	urlcolor   = MidnightBlue,
	colorlinks = true,
}

\begin{document}

	% Title
	\title{Single Image Super-Resolution and Denoising using Convolutional Neural Networks}
	\author{Guillermo Ruiz Álvarez}
	\institute{University of Málaga - \email{grabmct@uma.es}}
	
	\maketitle
	
	\abstract{We analyze the behavior of applying two well-known deep learning methods for single image super-resolution and image denoising, namely FSRCNN \cite{FSRCNN} and IRCNN \cite{IRCNN}, in different order to evaluate their combined capability to restore low resolution images with presence of noise. In order not to limit the case study to a single type of noise, Gaussian noise, Poisson noise, salt-and-pepper noise and uniform noise are applied to down-scaled images in order to construct the degraded images to be restored. As a result, we find that applying IRCNN before super-resolving the images with FSRCNN shows better results than using the networks in the opposite order for all types of noise. We also compare the quality achieved by using these deep learning methods in combination with other traditional algorithms: bicubic interpolation for super-resolution and median and wavelet filtering for image denoising. Our experimental results show that FSRCNN and IRCNN achieve better restoration quality than when the selected traditional methods are applied.
	
	\keywords{Single Image Super-Resolution, Image Denoising, Image Restoration, Convolutional Neural Networks.}\\~
	
	\textbf{Supervisors:} Ezequiel López Rubio, Rafael Marcos Luque Baena.
	
	\input{sections/1_introduction.tex}
	\input{sections/2_background.tex}
	\input{sections/3_deep_learning.tex}
	\input{sections/4_experimental_design.tex}
	\input{sections/5_experiments.tex}
	\input{sections/6_conclusions.tex}
	
	\newpage
	\printbibliography
	\printnoidxglossary[type=acronym]
	\printacronyms

\end{document}
