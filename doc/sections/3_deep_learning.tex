% !TeX spellcheck = en_US
\section{Deep Learning for SISR and noise reduction}\label{sec:deep_learning}

\subsection{Deep Learning for Single Image Super-Resolution}
Recently, deep learning methods for \gls{sisr} have demonstrated promising performance and accuracy compared to conventional \gls{sisr} algorithms. Before \gls{srcnn} \cite{SRCNN} was presented, which is the pioneer work in the field, Yang et al. \cite{SISRBENCH} categorized \gls{sisr} algorithms in 4 groups based on the image prior:
\begin{itemize}
	\item Prediction models, that apply a predefined mathematical formula to generate \gls{hr} outputs without training data. Bilinear, bicubic and Lanczos interpolation methods are examples of algorithms in this group.
	\item Edge based methods, that learn priors from edge features in order to predict \gls{hr} images from \gls{lr} images.
	\item Image statistical methods, that use statistical properties of the images as priors to reconstruct the \gls{hr} images.
	\item Patch based methods, that learn mapping functions from sets of paired \gls{lr} and \gls{hr} training images.
\end{itemize}

With the publication of \gls{srcnn} \cite{SRCNN}, deep learning methods can be added to this taxonomy. Within this category, multiple methods using different kinds of neural network have been developed. 

Kim et al. proposed \gls{vdsr} \cite{VDSR}, that uses similar structure as \gls{srcnn} but using a deeper network.

\gls{espcn} \cite{ESPCN} was proposed by Shi et al to make \gls{srcnn} more efficient. This network performs the feature extraction in the \gls{lr} space in order to consume less computational resources. Once the extraction is done, it uses a sub-pixel convolution in order to reconstruct the \gls{hr} image.

Dong et al. designed \gls{fsrcnn} \cite{FSRCNN} by accelerating \gls{srcnn} \cite{SRCNN} in multiple steps. First, the last convolution layer of \gls{srcnn} was replaced by a deconvolution layer, eliminating the need for using bicubic interpolation on the input \gls{lr} image. Second, the non-linear mapping layer was replaced by a shrinking layer, 4 non-linear mapping layer and an expanding layer, increasing the number of layers but reducing the number of parameters.

Residual networks have also been used for the \gls{sisr} task \cite{EDSR}\cite{REDNET}. These networks use skip connections to jump over some of their layers in order to tackle the problem of gradient vanishing, allowing to design very deep networks.

Lai et al. proposed \gls{lapsrn} \cite{LAPSRN}\cite{LAPSRN2}, based on a Laplacian pyramid framework, that progressively reconstructs the sub-band residuals from its feature extraction branch in order to obtain the \gls{hr} images. 

Some image denoisers, such as \gls{ircnn} \cite{IRCNN} and \gls{dncnn} \cite{DNCNN} also address the problem of \gls{sisr}. These methods model the image degradation in the \gls{sisr} problem by taking the noise as the difference between the \gls{hr} image and the bicubic upsampling of the \gls{lr} image.
 
\gls{gan} have also been used for \gls{sisr} \cite{SRGAN}. In these models, two neural networks contest with each other, in the context of game theory, in order to solve the super-resolution problem. The generative network generates output data by super-resolving \gls{lr} images and the discriminative network evaluates them. The objective of the discriminative network is to distinguish between real \gls{hr} images and super-resolved images while the generative network tries to increase its error rate.

Anwar et al. \cite{DBLP:SISR} proposed a taxonomy that categorizes deep learning methods for \gls{sisr} into 9 different groups according to their model designs, namely, linear networks, residual networks, recursive networks, progressive reconstruction designs, densely connected networks, multi-branch designs, attention based networks, multiple degradation handling networks and \gls{gan} models.

\subsection{Deep Learning for Image Denoising}
Image denoising is another important task in computer vision applications. Over the past years, multiple methods for modeling image priors, such as \gls{mrf} \cite{MRF}, \gls{bm3d} \cite{BM3D} and \gls{ncsr} \cite{NCSR}, have been proposed in order to tackle this problem. However, the mentioned methods have shown high computational cost and they also need to have their parameters manually chosen in order to improve performance \cite{DBLP:DEEPNR}. Multiple methods have been proposed to solve these problems. 

In \cite{TNRD}, Chen et al. presented a  \gls{tnrd} model in which the filters and the influence functions can be learned from the training data., 

In \cite{DEEPAM}, Kim et al. proposed \gls{deepam}, which learns a regularizer via deep aggregation in order to solve multiple image restoration tasks, including single image denoising.  

Zhang et al. proposed \gls{dncnn} \cite{DNCNN}, which uses residual learning and batch normalization in order to speed up the training process and boost the denoising performance.

Zhang et al. also proposed \gls{ircnn} \cite{IRCNN}, which is a \gls{cnn} based image denoiser that can be used for several low-level computer vision tasks such as \gls{sisr} or deblurring. \gls{ircnn} uses \gls{hqs} to show that a \gls{cnn} based denoiser prior can be plugged as a modular part of model-based optimization methods in order to solve multiple inverse problems.

In \cite{DILATED}, Wang et al. present a dilated residual \gls{cnn} for Gaussian image denoising in which the receptive field is enlarged by adopting dilated convolution.

\subsection{FSRCNN and IRCNN}
In this subsection, we review the structure of the two \glspl{cnn} used in this study: \gls{fsrcnn} and \gls{ircnn}.

\subsubsection{FSRCNN} The structure of \gls{fsrcnn} is composed of 5 different layers, 4 convolution layers and a deconvolution layer:
\begin{itemize}
	\item \textbf{Feature extraction}. This operation extracts overlapping patches from the \gls{lr} input by convolving them with a set of $d$ filters that represent each patch as a high dimensional feature vector. The size of the filters proposed by the authors for this layer is $5$. On the other hand, the input number of channels is $1$.
	\item \textbf{Shrinking}. A shrinking layer is added after the feature extraction in order to reduce the \gls{lr} feature dimension by convolving the \gls{lr} features with $s$ filters of size $1$. With this filter size, linear combinations applied in the  \gls{lr} feature space reduce its dimension from $d$ to $s$, decreasing as well the number of parameters and therefore the computational cost.
	\item \textbf{Non-linear mapping}. 
	\item Expanding:
	\item Deconvolution:
\end{itemize}

Following the notation proposed in \cite{fsrcnn}, we denote the convolution layers as $Conv(f_i, n_i, c_i)$ and the deconvolution layer as $DeConv(f_i, n_i, c_i)$ where $f_i$ is the size of the filter, $n_i$ is the number of filters and $c_i$ is the number of channels in the $i-th$ layer.

\subsubsection{IRCNN}
